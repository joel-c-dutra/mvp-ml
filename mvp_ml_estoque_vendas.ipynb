{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cdSc84z0seSG",
        "Jqe_14a6RKJL",
        "9B-JnkaURYnK",
        "RTF-H1btRuQG",
        "ynqVR0grClS5",
        "09H7GRVdWiZW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PUC Rio | MVP | Machine Learning\n",
        "\n",
        "Aluno: Joel Carneiro Dutra\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AyoOdAxdp6_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Definição do Problema:**\n",
        "\n",
        "Uma empresa que possui várias franquias de lojas, precisa prever a quantidade de produtos que cada franquia precisará para manter seus estoques otimizados. O objetivo é garantir que cada franquia tenha o estoque adequado para atender à demanda de seus clientes, minimizando ao mesmo tempo os custos de armazenamento e o risco de falta de produtos."
      ],
      "metadata": {
        "id": "uWF_3T3Hp2KS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passo 1: Coleta de Dados**\n",
        "\n",
        "A empresa coleta dados históricos de vendas e estoque de cada uma das franquias, juntamente com informações sobre sazonalidade, promoções, dados geográficos, entre outros fatores que podem influenciar a demanda.\n",
        "\n",
        "Esta etapa foi realizada por meio de uma extração no Google BigQuery, contendo os seguintes campos:\n",
        "\n",
        "- **dt_venda** - Data em que a venda foi realizada\n",
        "- **loja** - Código das franquias que realizaram as vendas\n",
        "- **uf** - UF das franquias (contendo Rio de Janeiro e São Paulo)\n",
        "- **produto** - Descrição do produto vendido (Produto X, Y e Z)\n",
        "- **canal_venda** - Canal onde ocorreu a venda (Loja ou Site)\n",
        "- **tipo_venda** - Tipo de venda (Promoção ou Regular)\n",
        "- **vlr_venda** - Valor total da venda\n",
        "- **qt_venda** - Quantidade de itens vendidos\n",
        "\n",
        "Atributos:\n",
        "- **qt_dias_com_estoque** - Quantidade de dias em que a loja tinha estoque\n",
        "- **qt_dias_sem_estoque** - Quantidade de dias em que a loja não tinha estoque\n",
        "- **qt_dias_com_estoque_aberta** - Quantidade de dias em que a loja tinha estoque e estava aberta para venda\n",
        "- **qt_dias_sem_estoque_aberta** - Quantidade de dias em que a loja não tinha estoque e estava aberta para venda\n",
        "- **qt_dias_loja_fechada** - Quantidade de dias em que a loja esteve fechada\n",
        "- **estoque_loja** - Quantidade de estoque da loja\n",
        "- **habilitador** - Determina se a loja deverá ser abastecida caso tenha menos que 5 itens em seu estoque (variável 1 ou 0)"
      ],
      "metadata": {
        "id": "cdSc84z0seSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Imports necessários\n",
        "import requests\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as ms\n",
        "from matplotlib import cm\n",
        "from pandas import set_option\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "gkpWUjzvuSqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passo 2: Carga dos Dados**\n",
        "\n",
        "Nessa etapa fazemos a conexão com o dataset, fazendo a requisição do arquivo em formato .csv e a leitura do arquivo em um DataFrame."
      ],
      "metadata": {
        "id": "Jqe_14a6RKJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Opção de leitura #1 - Origem GitHub`"
      ],
      "metadata": {
        "id": "G6LnjcL6Km2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/joel-c-dutra/mvp-ml/main/base_historica.csv'\n",
        "\n",
        "# Leitura do arquivo CSV em um DataFrame\n",
        "page = requests.get(url)\n",
        "\n",
        "dataset = pd.read_csv(StringIO(page.text))\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "J-qNz0zEDyCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/joel-c-dutra/mvp-ml/main/base_historica.csv\"\n",
        "\n",
        "# Informa o cabeçalho das colunas\n",
        "colunas = ['dt_venda', 'loja', 'uf', 'produto', 'canal_venda', 'tipo_venda', 'vlr_venda', 'qt_venda', 'qt_dias_com_estoque', 'qt_dias_sem_estoque', 'qt_dias_com_estoque_aberta', 'qt_dias_sem_estoque_aberta', 'qt_dias_loja_fechada', 'estoque_loja', 'habilitador']\n",
        "\n",
        "# Lê o arquivo utilizando as colunas informadas\n",
        "dataset = pd.read_csv(url, names=colunas, skiprows=1, delimiter=',')\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "2fnY9qtTYOXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Opção de leitura #2 - Origem Google Drive`"
      ],
      "metadata": {
        "id": "noghP9bWLFT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "caminho_arquivo = '/content/drive/My Drive/datasets/base_historica.csv'\n",
        "\n",
        "# Leitura do arquivo CSV em um DataFrame\n",
        "dataset = pd.read_csv(caminho_arquivo)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "xHz7Mkp_IwP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Referenciando os atribuitos a uma nova variável\n",
        "dataset_atributos = dataset.loc[:, ['qt_dias_com_estoque', 'qt_dias_sem_estoque', 'qt_dias_com_estoque_aberta', 'qt_dias_sem_estoque_aberta', 'qt_dias_loja_fechada', 'habilitador']]\n",
        "dataset_atributos.head()"
      ],
      "metadata": {
        "id": "6uGcgPNIy6lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passo 3: Análise dos Dados**\n",
        "\n",
        "Nesta etapa é apresentado algumas informações do dataset, tais como:\n",
        "\n",
        "- Volume de registros\n",
        "- Tipo de dado de cada atributo\n",
        "- Descrição dos campos"
      ],
      "metadata": {
        "id": "9B-JnkaURYnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 - Volume de registros**"
      ],
      "metadata": {
        "id": "tTWOWDfYz7TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra as dimensões do dataset\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "id": "BGgg56Wa-GHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 - Tipo de dado de cada atributo**"
      ],
      "metadata": {
        "id": "Qa0Gkf8m0EFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra as informações do dataset\n",
        "print(dataset.info())"
      ],
      "metadata": {
        "id": "v_HtGK4A-LiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica o tipo de dataset de cada atributo\n",
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "k9kdvPg9wWzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 - Descrição dos campos**"
      ],
      "metadata": {
        "id": "gRzIS4r-0KYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Faz um resumo estatístico do dataset (média, desvio padrão, mínimo, máximo e os quartis)\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "AeO2xiLbwc1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passo 4: Pré-Processamento dos Dados**\n",
        "\n",
        "\n",
        "\n",
        "Nesta etapa realizamos os seguintes processos:\n",
        "\n",
        "- Verificação por campos nulos;\n",
        "- Distribuição da classe;\n",
        "- Histograma e Matriz de Correlação;\n",
        "- Feature Selection."
      ],
      "metadata": {
        "id": "RTF-H1btRuQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1 - Campos nulos**"
      ],
      "metadata": {
        "id": "edJi3Hc4eFF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando nulls no dataset\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "PfEOKNcb2DNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 - Distribuição da classe**"
      ],
      "metadata": {
        "id": "RXVz6tEoeLzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distribuição da classe\n",
        "print(dataset.groupby('habilitador').size())"
      ],
      "metadata": {
        "id": "tjrEgl5K61OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Referenciando os atribuitos a uma nova variável\n",
        "dataset_atributos = dataset.loc[:, ['qt_dias_com_estoque', 'qt_dias_sem_estoque', 'qt_dias_com_estoque_aberta', 'qt_dias_sem_estoque_aberta', 'qt_dias_loja_fechada', 'habilitador']]\n",
        "dataset_atributos.head()"
      ],
      "metadata": {
        "id": "hlgNurWR4bP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 - Histograma e Matriz de Correlação**"
      ],
      "metadata": {
        "id": "7P5ZpK3yd2uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma\n",
        "dataset_atributos.hist(figsize = (15,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZEQB_hHRw-4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Density Plot\n",
        "dataset_atributos.plot(kind = 'density', subplots = True, layout = (3,3), sharex = False, figsize = (15,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sjyrZ_eAxVYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de Correlação com Matplotlib Seaborn\n",
        "sns.heatmap(dataset_atributos.corr(), annot=True, cmap='RdBu');"
      ],
      "metadata": {
        "id": "0nM5B5hXyLT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na etapa acima (Matriz de Correlação) já é possível analisar os atributos mais prováveis para utilização no(s) modelo(s).\n",
        "\n",
        "Os mesmos são apresentados também no processo a seguir (Feature Selection)."
      ],
      "metadata": {
        "id": "K-52nYygc4L1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.4 - Feature Selection**"
      ],
      "metadata": {
        "id": "b4aWbMz8SOA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação dos dados para Feature Selection\n",
        "\n",
        "# Separação em bases de treino e teste (holdout)\n",
        "array = dataset_atributos.values\n",
        "X = array[:,0:5] # atributos\n",
        "y = array[:,5]   # classe (target)"
      ],
      "metadata": {
        "id": "kdcPXVL2F7h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SelectKBest\n",
        "\n",
        "# Seleção de atributos com SelectKBest\n",
        "best_var = SelectKBest(score_func=f_classif, k=3)\n",
        "\n",
        "# Executa a função de pontuação em (X, y) e obtém os atributos selecionados\n",
        "fit = best_var.fit(X, y)\n",
        "\n",
        "# Reduz X para os atributos selecionados\n",
        "features = fit.transform(X)\n",
        "\n",
        "# Resultados\n",
        "print('\\nNúmero original de atributos:', X.shape[1])\n",
        "print('\\nNúmero reduzido de atributos:', features.shape[1])\n",
        "\n",
        "# Exibe os atributos orginais\n",
        "print(\"\\nAtributos Originais:\", dataset_atributos.columns[0:6])\n",
        "\n",
        "# Exibe as pontuações de cada atributos e os 4 escolhidos (com as pontuações mais altas)\n",
        "np.set_printoptions(precision=3) # 3 casas decimais\n",
        "print(\"\\nScores dos Atributos Originais:\", fit.scores_)\n",
        "print(\"\\nAtributos Selecionados:\", best_var.get_feature_names_out(input_features=dataset_atributos.columns[0:5]))"
      ],
      "metadata": {
        "id": "rhGzCt_LGyr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminação Recursiva de Atributos\n",
        "\n",
        "# Criação do modelo\n",
        "modelo = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Eliminação Recursiva de Atributos\n",
        "rfe = RFE(modelo, n_features_to_select=3)\n",
        "fit = rfe.fit(X, y)\n",
        "\n",
        "# Print dos resultados\n",
        "print(\"Atributos Originais:\", dataset_atributos.columns[0:6])\n",
        "\n",
        "# Exibe os atributos selecionados (marcados como True em \"Atributos Selecionados\"\n",
        "# e com valor 1 em \"Ranking dos Atributos\")\n",
        "print(\"\\nAtributos Selecionados: %s\" % fit.support_)\n",
        "print(\"\\nRanking de atributos: %s\" % fit.ranking_)\n",
        "print(\"\\nQtd de melhores Atributos: %d\" % fit.n_features_)\n",
        "print(\"\\nNomes dos Atributos Selecionados: %s\" % fit.get_feature_names_out(input_features=dataset_atributos.columns[0:5]))"
      ],
      "metadata": {
        "id": "PNPhosbUz0Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao utilizar o **SelectKBest** e a **Eliminação Recursiva**, foi possível determinar dois campos em comum em ambas as análises:\n",
        "- *qt_dias_sem_estoque*\n",
        "- *qt_dias_com_estoque_aberta*\n",
        "\n",
        "Sendo assim, serão utilizados esses dois atributos no processo de treino e teste do(s) modelo(s)."
      ],
      "metadata": {
        "id": "D2rqmoB0sJsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passo 5: Separação em conjunto de treino e teste**\n",
        "\n",
        "Nesta etapa foram realizados os seguintes processos:\n",
        "\n",
        "- Holdout (com estratificação)\n",
        "- Teste e comparação dos modelos\n",
        "- Validação cruzada (Pipeline)"
      ],
      "metadata": {
        "id": "ynqVR0grClS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.1 - Holdout com estratificação**"
      ],
      "metadata": {
        "id": "daCoUnOsVWH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.20 # tamanho do conjunto de teste\n",
        "seed = 7 # semente aleatória\n",
        "\n",
        "# Separação em conjuntos de treino e teste\n",
        "array = dataset_atributos.values\n",
        "X = array[:,[1,2]]\n",
        "y = array[:,5]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "    test_size=test_size, shuffle=True, random_state=seed, stratify=y) # holdout com estratificação\n",
        "\n",
        "# Parâmetros e partições da validação cruzada\n",
        "scoring = 'accuracy'\n",
        "num_particoes = 10\n",
        "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # Validação cruzada"
      ],
      "metadata": {
        "id": "GwkO5XniH5l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2 - Teste e comparação dos modelos**"
      ],
      "metadata": {
        "id": "fFyOwXWgiQd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7) # definindo uma semente global\n",
        "\n",
        "# Lista que armazenará os módulos\n",
        "models = []\n",
        "\n",
        "# Criando os modelos e adicionando-os na lista de modelos\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Definindo os parâmetros do classificador base o BaggingClassifier\n",
        "base = DecisionTreeClassifier()\n",
        "num_trees = 4\n",
        "max_features = 2\n",
        "\n",
        "# Criando os modelos para o VotingClassifier\n",
        "bases = []\n",
        "model1 = DecisionTreeClassifier()\n",
        "bases.append(('cart', model1))\n",
        "model2 = SVC()\n",
        "bases.append(('svm', model2))"
      ],
      "metadata": {
        "id": "N5PR_kAaI9hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando os ensembles e adicionando-os na lista de modelos\n",
        "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))"
      ],
      "metadata": {
        "id": "UBdkirwdL23p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar os resultados\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliação dos modelos\n",
        "for name, model in models:\n",
        "  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "i5qXFpxUMluX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base nos resultados apresentados, foi possível analisar que o modelo **Random Forest** foi o que apresentou o melhor resultados na comparação entre os modelos, com os seguintes resultados:\n",
        "\n",
        "\n",
        "- RF:      0.723891 (0.029982)\n",
        "- CART:    0.723200 (0.021741)\n",
        "- ET:      0.723200 (0.021741)\n",
        "- GB:      0.656366 (0.017241)\n",
        "- SVM:     0.630786 (0.017767)\n"
      ],
      "metadata": {
        "id": "PDoUQAIBifnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "fig.suptitle('Comparação dos Modelos')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KexAUVT2OYd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.3 - Validação cruzada (Pipeline)**"
      ],
      "metadata": {
        "id": "JrsATp57lBSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a escolha do modelo, foi feita a comparação entre os dados:\n",
        "\n",
        "- Original\n",
        "- Padronizado\n",
        "- Normalizado"
      ],
      "metadata": {
        "id": "09H7GRVdWiZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7) # definindo uma semente global para este bloco\n",
        "\n",
        "# Lista para armazenar os pipelines e os resultados para todas as visões do dataset\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Criando os elementos do pipeline\n",
        "\n",
        "random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "\n",
        "# Transformações que serão utilizadas\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())"
      ],
      "metadata": {
        "id": "kOuQUC62sltK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Montando os pipelines\n",
        "\n",
        "# Dataset original\n",
        "pipelines.append(('RF-orig', Pipeline([random_forest])))\n",
        "\n",
        "# Dataset padronizado\n",
        "pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))\n",
        "\n",
        "# Dataset normalizado\n",
        "pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))\n",
        "\n",
        "# Executando os pipelines\n",
        "for name, model in pipelines:\n",
        "  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "faYUA6ctuW66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base nos resultados obtidos, nota-se uma pequena variação entre os dados.\n",
        "\n",
        "- RF-orig: 0.729 (0.027)\n",
        "- RF-padr: 0.723 (0.022)\n",
        "- RF-norm: 0.726 (0.023)"
      ],
      "metadata": {
        "id": "4uBkpEBTl2u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(20,6))\n",
        "fig.suptitle('Comparação dos Modelos - Dataset original, padronizado e normalizado')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names, rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4SsTE_fNyrjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passo 6: Avaliação do modelo**"
      ],
      "metadata": {
        "id": "2UuDU4DA1X3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta etapa foi realizada a avaliação do modelo em conjunto de teste"
      ],
      "metadata": {
        "id": "r274GlXU1kjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação do modelo com o conjunto de testes\n",
        "\n",
        "# Preparação do modelo\n",
        "scaler = StandardScaler().fit(X_train) # ajuste do scaler com o conjunto de treino\n",
        "rescaledX = scaler.transform(X_train) # aplicação da padronização no conjunto de treino\n",
        "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
        "model.fit(rescaledX, y_train)\n",
        "\n",
        "# Estimativa da acurácia no conjunto de teste\n",
        "rescaledTestX = scaler.transform(X_test) # aplicação da padronização no conjunto de teste\n",
        "predictions = model.predict(rescaledTestX)\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "4dWbHG425t2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base no resultado obtido, verificou-se que a acurácia foi de **72,99%**."
      ],
      "metadata": {
        "id": "H5d9cpikmXm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Passo 7: Aplicação em produção**\n",
        "\n",
        "Nesta etapa, após a escolha do modelo, foi realizado o uso do mesmo com novos dados"
      ],
      "metadata": {
        "id": "5FTHR1rw8Heo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação do modelo com todo o dataset\n",
        "scaler = StandardScaler().fit(X) # ajuste do scaler com todo o dataset\n",
        "rescaledX = scaler.transform(X) # aplicação da padronização com todo o dataset\n",
        "model.fit(rescaledX, y)"
      ],
      "metadata": {
        "id": "Ah5VkdHZ8OIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulação com novos dados\n",
        "\n",
        "data = {\n",
        "        'qt_dias_sem_estoque': [3, 5, 0],\n",
        "        'qt_dias_com_estoque_aberta': [7, 28, 10],\n",
        "        }\n",
        "\n",
        "atributos = ['qt_dias_sem_estoque', 'qt_dias_com_estoque_aberta']\n",
        "entrada = pd.DataFrame(data, columns=atributos)\n",
        "\n",
        "array_entrada = entrada.values\n",
        "X_entrada = array_entrada[:,0:2].astype(float)\n",
        "\n",
        "# Padronização nos dados de entrada usando o scaler utilizado em X\n",
        "rescaledEntradaX = scaler.transform(X_entrada)\n",
        "print(rescaledEntradaX)"
      ],
      "metadata": {
        "id": "bixW34219QM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predição de classes dos dados de entrada\n",
        "\n",
        "saidas = model.predict(rescaledEntradaX)\n",
        "print(saidas)"
      ],
      "metadata": {
        "id": "uj_EbrO6AaaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante a simulação, foram incluídos novos dados para avaliar o modelo, onde o mesmo trouxe com sucesso o resultado: [1, 0, 1].\n",
        "\n",
        "Dessa forma, foi possível prever que a segunda franquia não precisaria de abastecimento.\n",
        "\n",
        "No entanto, existiria a necessidade da primeira e a terceira franquia repor seus estoques."
      ],
      "metadata": {
        "id": "GjVFvSKXnYxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusão**\n",
        "\n",
        "- Durante os primeiros testes realizados, o atributo *estoque_loja* foi utilizado para avaliação dos modelos, o que consequentemente causou overfitting em 3 dos 5 modelos utilizados: DecisionTree, RandomForest e GradientBoosting, retornando 100% cada um. Já os modelos SVM e ExtraTrees, retornaram cerca de 58% de acurácia.\n",
        "\n",
        "- Ao utilizar 2 dos 3 atributos obtidos por meio do processo de Feature Selection, foi possível determinar melhores resultados entre os modelos.\n",
        "\n",
        "- A utilização da estratificação com holdout permitiu que o modelo fosse avaliado de forma justa e imparcial, garantindo a capacidade de generalizar adequadamente para novos dados inseridos posteriormente.\n",
        "\n",
        "- Apesar de apresentar 2 outliers previstos para cima, o RandomForest se mostrou com melhor resultado durante os testes, apresentando 72,99% de acurácia."
      ],
      "metadata": {
        "id": "zd8qHWzaXtlS"
      }
    }
  ]
}